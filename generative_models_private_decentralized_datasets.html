Summary: Generative Models for Effective ML on Private Decentralized Datasets
Modelers enhance ML systems by analyzing datasets and model-data interaction. Manual inspection of

raw data generally helps fix problems in dataset, to generate model hypothesis, also to refine human-
assigned labels. Manual data inspection is problematic for private datasets and in Federated Learning

(FL) where the modeler has access only to aggregated outputs. Common data issues have been selected
from recent work (Humbatova et al 2019) which classifies these into 6 different categories (T1-T6,
shown in Fig. 1 below). The paper shows that Generative models trained using FL with DP guarantees
can be used to debug data issues (T1-T5) without direct inspection of data. They illustrate this by taking
advantage of generative model architectures like RNNs and GANs for debugging. For text they apply
their previous work for FL using DP for RNNs (McMahan et al 2018) and develop a new algorithm for
images using FL for GANs using DP with promising bounds for a large dataset. They propose challenges
and potential directions for future work to inspect/resolve other data issues (T6).
Fig 1:


To find existing bugs in the dataset on edge devices, a copy of an uninitialized generative network
residing at the server along with fake data generated by the network can be shared with a set of
sampled devices, that can train the network on their respective datasets. The weights of the
discriminator can then be clipped, aggregated and noised to backpropagate and update weights on the
generator iteratively. The modeler can then look at generated data on the server to inspect and address
bugs. The paper illustrates how inverted pixels show up when two separate GANs are trained on high
accuracy/low accuracy examples shown in the paper. RNNs can be used similarly by keeping generative
models (word-LMs, char-LMs) on the server and using updates from edge nodes to generate words
indicative of potential issues like tokenization errors or OOV words.
The idea of detecting bugs in the dataset using generative models at the server is novel since this
architecture can take advantage of the fact that the generator does not need real data to train on and
the discriminator can compute gradient aggregates from edge nodes to update gradients based on real
data, also that these two sub-networks train iteratively helps. Applying (∊; δ) DP bounds to this method
which is only required for discriminator network enables user level privacy. This work has a lot of
potential even though a lot of research is yet to be done for data issues that have not been addressed
and finding convergence in GANs without extensive experimentation (may compromise privacy).
Issues: There are data bugs like debiasing trained models that lack enough samples from a class on edge
nodes during training. A discriminator trained on server to indicate the presence of data belonging to a
class requires training on cloud datasets. This can be a challenging task in FL.
